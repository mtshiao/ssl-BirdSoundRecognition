{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b151a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert audio to mono\n",
    "import os\n",
    "import torchaudio\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "def convert_to_mono(filepath, output_path):\n",
    "    audio, sample_rate = torchaudio.load(filepath)\n",
    "    if audio.shape[0] == 2:\n",
    "        mono = torch.mean(audio, dim=0, keepdim=True)\n",
    "        torchaudio.save(output_path, mono, sample_rate)\n",
    "    else:\n",
    "        print(f\"The audio at {filepath} is not stereo.\")\n",
    "\n",
    "def convert_folder_to_mono(input_dir, output_dir):\n",
    "    wav_files = [f for f in os.listdir(input_dir) if f.endswith('.wav')]\n",
    "    for wav_file in tqdm(wav_files, desc=\"Converting files\"):\n",
    "        input_path = os.path.join(input_dir, wav_file)\n",
    "        output_path = os.path.join(output_dir, wav_file)\n",
    "        convert_to_mono(input_path, output_path)\n",
    "\n",
    "\n",
    "input_dir = str(Path.cwd().parents[2].joinpath('Audio_data', 'finetune_Audio'))\n",
    "output_dir = str(Path.cwd().parents[2].joinpath('Audio_data', 'finetune_Audio_mono'))\n",
    "convert_folder_to_mono(input_dir, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a3cedb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Generate label class\n",
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "# -------------------------------------------------------------------------------------- #\n",
    "\n",
    "input_csv_path = str(Path.cwd().parents[2].joinpath('Audio_data', 'setting', 'species.csv'))\n",
    "output_csv_path = str(Path.cwd().parents[2].joinpath('Audio_data', 'finetune_labels_indices.csv'))\n",
    "add_dummy_label = False\n",
    "add_nota = True\n",
    "\n",
    "# -------------------------------------------------------------------------------------- #\n",
    "\n",
    "with open(input_csv_path, \"r\") as input_file:\n",
    "    reader = csv.DictReader(input_file)\n",
    "    rows = [row for row in reader if row[\"target\"] == \"TRUE\"]\n",
    "with open(output_csv_path, \"w\") as output_file:\n",
    "    fieldnames = [\"index\", \"mid\", \"display_name\"]\n",
    "    writer = csv.DictWriter(output_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    if add_dummy_label:\n",
    "        writer.writerow({\"index\": 0, \"mid\": \"/m/dummy\", \"display_name\": \"dummy\"})\n",
    "        start_index = 1\n",
    "    else:\n",
    "        start_index = 0\n",
    "\n",
    "    for index, row in enumerate(rows, start=start_index):\n",
    "        writer.writerow({\n",
    "            \"index\": index,\n",
    "            \"mid\": f\"/m/bs{str(index).zfill(2)}\",\n",
    "            \"display_name\": row[\"code\"]\n",
    "        })\n",
    "    if add_nota:\n",
    "        writer.writerow({\n",
    "            \"index\": index + 1,\n",
    "            \"mid\": f\"/m/bs{str(index + 1).zfill(2)}\",\n",
    "            \"display_name\": \"NoneOfTheAbove\"\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce68224",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torchaudio\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def generate_segments(audio_path, audio_duration, segment_duration=1, gap=0.25):\n",
    "    num_segments = int(np.ceil((audio_duration - segment_duration) / gap))\n",
    "    segments = []\n",
    "\n",
    "    for i in range(num_segments):\n",
    "        start_time = i * gap\n",
    "        end_time = start_time + segment_duration\n",
    "        segments.append({\n",
    "            \"wav\": audio_path,\n",
    "            \"start_time\": start_time,\n",
    "            \"end_time\": end_time\n",
    "        })\n",
    "    return segments\n",
    "\n",
    "def buil_json_data(audio_directories=None, \n",
    "                   label_directories=None,\n",
    "                   out_put_path=None,\n",
    "                   segment_duration=1,\n",
    "                   gap=0.25, \n",
    "                   compare_gap=0.4,\n",
    "                   min_time_threshold=0.1,\n",
    "                   finetune_labels_csv=None,\n",
    "                   enable_deletion=True,\n",
    "                   trans_label_neme=True,\n",
    "                   AS_switch=True):\n",
    "\n",
    "    audio_files = []\n",
    "    for audio_directory_list in audio_directories:\n",
    "        audio_directory = audio_directory_list[0]\n",
    "        for filename in os.listdir(audio_directory):\n",
    "            if filename.endswith(\".wav\"):\n",
    "                audio_files.append(filename[:-4])\n",
    "\n",
    "    filtered_segments = []\n",
    "    for base_filename in tqdm(audio_files):\n",
    "        audio_path = None\n",
    "        txt_path = None\n",
    "\n",
    "        for audio_directory_list in audio_directories:\n",
    "            audio_directory = audio_directory_list[0]\n",
    "            possible_path = os.path.join(audio_directory, base_filename + \".wav\")\n",
    "            if os.path.isfile(possible_path):\n",
    "                audio_path = possible_path\n",
    "                break\n",
    "\n",
    "        for label_directory in label_directories:\n",
    "            possible_path = os.path.join(label_directory, base_filename + \".txt\")\n",
    "            if os.path.isfile(possible_path):\n",
    "                txt_path = possible_path\n",
    "                break\n",
    "\n",
    "        if audio_path is None or txt_path is None:\n",
    "            print(f\"Skipped {base_filename} as corresponding file not found.\")\n",
    "            continue\n",
    "\n",
    "        waveform, sample_rate = torchaudio.load(audio_path)\n",
    "        audio_duration = waveform.shape[1] / sample_rate\n",
    "\n",
    "        segments = generate_segments(audio_path, audio_duration, segment_duration, gap)\n",
    "\n",
    "        with open(txt_path, \"r\") as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        intervals_and_labels = []\n",
    "        for line in lines:\n",
    "            start, end, label = line.split()\n",
    "            intervals_and_labels.append({\n",
    "                \"start\": float(start),\n",
    "                \"end\": float(end),\n",
    "                \"label\": label\n",
    "            })\n",
    "\n",
    "        labeled_segments = []\n",
    "\n",
    "        for segment in segments:\n",
    "            label_names = []\n",
    "            delete_flag = False\n",
    "            for interval_and_label in intervals_and_labels:\n",
    "                if (segment[\"start_time\"] < interval_and_label[\"end\"] and segment[\"end_time\"] > interval_and_label[\"start\"]):\n",
    "                    overlap_start = max(segment[\"start_time\"], interval_and_label[\"start\"])\n",
    "                    overlap_end = min(segment[\"end_time\"], interval_and_label[\"end\"])\n",
    "                    overlap_time = overlap_end - overlap_start\n",
    "                    if overlap_time >= compare_gap:\n",
    "                        label_names.append(interval_and_label[\"label\"])\n",
    "                    elif min_time_threshold <= overlap_time < compare_gap:\n",
    "                        if enable_deletion:\n",
    "                            delete_flag = True\n",
    "                            break\n",
    "            if label_names and not delete_flag:\n",
    "                filtered_segments.append({\n",
    "                    \"wav\": audio_path,\n",
    "                    \"start_time\": segment[\"start_time\"],\n",
    "                    \"end_time\": segment[\"end_time\"],\n",
    "                    \"labels\": \",\".join(label_names)\n",
    "                })\n",
    "\n",
    "        formatted_segments = {\"data\": filtered_segments}\n",
    "        with open(out_put_path, 'w') as json_file:\n",
    "            json.dump(formatted_segments, json_file, indent=2)\n",
    "\n",
    "    if trans_label_neme:\n",
    "        with open(out_put_path, 'r') as json_file:\n",
    "            data = json.load(json_file)\n",
    "        df = pd.read_csv(finetune_labels_csv)\n",
    "        name_to_mid = pd.Series(df.mid.values, index=df.display_name).to_dict()\n",
    "        processed_data = []\n",
    "        for entry in data['data']:\n",
    "            labels = entry['labels'].split(',')\n",
    "            valid_labels = []\n",
    "            for label in labels:\n",
    "                if '-' in label:\n",
    "                    species, sound_type = label.split('-')\n",
    "                    if species in name_to_mid and (sound_type.startswith('S') or (AS_switch and sound_type.startswith('AS'))):\n",
    "                        valid_labels.append(name_to_mid[species])\n",
    "            if valid_labels:\n",
    "                valid_labels = sorted(set(valid_labels))\n",
    "                entry['labels'] = ','.join(valid_labels)\n",
    "                processed_data.append(entry)\n",
    "        with open(out_put_path, 'w') as json_file:\n",
    "            json.dump({\"data\": processed_data}, json_file, indent=2)\n",
    "\n",
    "segment_duration = 1 \n",
    "gap = 0.25  \n",
    "compare_gap = 0.4 \n",
    "min_time_threshold = 0.1  \n",
    "enable_deletion = True  \n",
    "\n",
    "trans_label_neme = True \n",
    "finetune_labels_csv = str(Path.cwd().parents[2].joinpath('Audio_data', 'finetune_labels_indices.csv'))\n",
    "AS_switch = True \n",
    "\n",
    "audio_directories = [[str(Path.cwd().parents[2].joinpath('Audio_data', 'finetune_Audio_mono/'))]]\n",
    "label_directories = [str(Path.cwd().parents[2].joinpath('Audio_data', 'finetune_Label_txt'))]\n",
    "out_put_path = str(Path.cwd().parents[2].joinpath('temporary_file', 'segment.json'))\n",
    "buil_json_data(audio_directories=audio_directories, \n",
    "                   label_directories=label_directories,\n",
    "                   out_put_path=out_put_path,\n",
    "                   segment_duration=segment_duration,\n",
    "                   gap=gap, \n",
    "                   compare_gap=compare_gap,\n",
    "                   min_time_threshold=min_time_threshold,\n",
    "                   finetune_labels_csv=finetune_labels_csv,\n",
    "                   enable_deletion=enable_deletion,\n",
    "                   trans_label_neme=trans_label_neme,\n",
    "                   AS_switch=AS_switch)\n",
    "\n",
    "# open source\n",
    "audio_directories = [[str(Path.cwd().parents[2].joinpath('Audio_data', 'opensource_Audio_mono/'))]]\n",
    "label_directories = [str(Path.cwd().parents[2].joinpath('Audio_data', 'opensource_Label_txt'))]\n",
    "out_put_path = str(Path.cwd().parents[2].joinpath('temporary_file', 'opensource_segment.json'))\n",
    "buil_json_data(audio_directories=audio_directories, \n",
    "                   label_directories=label_directories,\n",
    "                   out_put_path=out_put_path,\n",
    "                   segment_duration=segment_duration,\n",
    "                   gap=gap, \n",
    "                   compare_gap=compare_gap,\n",
    "                   min_time_threshold=min_time_threshold,\n",
    "                   finetune_labels_csv=finetune_labels_csv,\n",
    "                   enable_deletion=enable_deletion,\n",
    "                   trans_label_neme=trans_label_neme,\n",
    "                   AS_switch=AS_switch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e35e6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Select 10% of files for the validation / testing dataset\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import shutil\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "wav_directory = str(Path.cwd().parents[2].joinpath('Audio_data', 'finetune_Audio_mono'))\n",
    "\n",
    "val_txt_path = str(Path.cwd().parents[2].joinpath('Audio_data', 'val_list.txt'))\n",
    "test_txt_path = str(Path.cwd().parents[2].joinpath('Audio_data', 'test_list.txt'))\n",
    "train_txt_path = str(Path.cwd().parents[2].joinpath('Audio_data', 'train_list.txt'))\n",
    "\n",
    "pick_probability_1 = 0.10\n",
    "pick_probability_2 = 0.10\n",
    "\n",
    "wav_files = os.listdir(wav_directory)\n",
    "regex = re.compile(r\"([A-Z0-9]+)_(\\d{8})_\\d{6}\\.wav\")\n",
    "\n",
    "counts = defaultdict(lambda: defaultdict(int))\n",
    "filenames = defaultdict(lambda: defaultdict(list))\n",
    "selected_counts_1 = defaultdict(lambda: defaultdict(int))\n",
    "selected_counts_2 = defaultdict(lambda: defaultdict(int))\n",
    "original_satisfying_dates = defaultdict(set)\n",
    "skipped_files = []\n",
    "\n",
    "copied_files_1 = []\n",
    "copied_files_2 = []\n",
    "remaining_files = []\n",
    "\n",
    "total = 0\n",
    "for file in wav_files:\n",
    "    match = regex.match(file)\n",
    "    if match:\n",
    "        station, date = match.group(1), match.group(2)\n",
    "        counts[station][date] += 1\n",
    "        filenames[station][date].append(file)\n",
    "        if counts[station][date] == 10:\n",
    "            original_satisfying_dates[station].add(date)\n",
    "        total += 1\n",
    "    else:\n",
    "        skipped_files.append(file)\n",
    "\n",
    "def process_files(sampled_files, selected_counts, station, date, copied_files):\n",
    "    for file in sampled_files:\n",
    "        selected_counts[station][date] += 1\n",
    "        copied_files.append(os.path.splitext(file)[0])\n",
    "\n",
    "for station in sorted(counts.keys()):\n",
    "    for date, files in sorted(filenames[station].items()):\n",
    "        if len(files) >= 10:\n",
    "            total_files = len(files)\n",
    "            num_to_sample_1 = int(total_files * pick_probability_1)\n",
    "            num_to_sample_2 = int(total_files * pick_probability_2)\n",
    "\n",
    "            sampled_files = random.sample(files, min(total_files, num_to_sample_1 + num_to_sample_2))\n",
    "            sampled_files_1 = sampled_files[:num_to_sample_1]\n",
    "            sampled_files_2 = sampled_files[num_to_sample_1:num_to_sample_1 + num_to_sample_2]\n",
    "\n",
    "            if sampled_files_1:\n",
    "                process_files(sampled_files_1, selected_counts_1, station, date, copied_files_1)\n",
    "\n",
    "            if sampled_files_2:\n",
    "                process_files(sampled_files_2, selected_counts_2, station, date, copied_files_2)\n",
    "\n",
    "    not_satisfying_files = [(date, files) for date, files in filenames[station].items() if len(files) < 10]\n",
    "    total_files = sum(len(files) for _, files in not_satisfying_files)\n",
    "    num_to_sample_1 = int(total_files * pick_probability_1)\n",
    "    num_to_sample_2 = int(total_files * pick_probability_2)\n",
    "\n",
    "    if not_satisfying_files:\n",
    "        dates_sampled_1 = random.sample(not_satisfying_files, min(len(not_satisfying_files), num_to_sample_1))\n",
    "        dates_sampled_2 = random.sample(not_satisfying_files, min(len(not_satisfying_files), num_to_sample_2))\n",
    "\n",
    "        for date, files in dates_sampled_1:\n",
    "            file_selected = random.choice(files)\n",
    "            process_files([file_selected], selected_counts_1, station, date, copied_files_1)\n",
    "\n",
    "        for date, files in dates_sampled_2:\n",
    "            file_selected = random.choice(files)\n",
    "            process_files([file_selected], selected_counts_2, station, date, copied_files_2)\n",
    "\n",
    "all_files = [os.path.splitext(file)[0] for file in wav_files]\n",
    "remaining_files = list(set(all_files) - set(copied_files_1) - set(copied_files_2))\n",
    "\n",
    "with open(val_txt_path, \"w\") as file:\n",
    "    file.write(\"\\n\".join(copied_files_1))\n",
    "\n",
    "with open(test_txt_path, \"w\") as file:\n",
    "    file.write(\"\\n\".join(copied_files_2))\n",
    "\n",
    "with open(train_txt_path, \"w\") as file:\n",
    "    file.write(\"\\n\".join(remaining_files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dbb395",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def process_files(json_filename, txt_filenames, output_paths):\n",
    "    with open(json_filename, 'r') as json_file:\n",
    "        json_data = json.load(json_file)['data']\n",
    "    \n",
    "    for txt_filename, output_path in zip(txt_filenames, output_paths):\n",
    "        with open(txt_filename, 'r') as txt_file:\n",
    "            txt_data = [line.strip().split('/')[-1].split('.')[0] for line in txt_file]\n",
    "        matched_data = [entry for entry in json_data if entry['wav'].split('/')[-1].split('.')[0] in txt_data]\n",
    "\n",
    "        with open(output_path, 'w') as output_file:\n",
    "            json.dump({\"data\": matched_data}, output_file, indent=4)\n",
    "\n",
    "json_filename = str(Path.cwd().parents[2].joinpath('temporary_file', 'segment.json'))\n",
    "txt_filenames = [\n",
    "    str(Path.cwd().parents[2].joinpath('Audio_data', 'train_list.txt')),\n",
    "    str(Path.cwd().parents[2].joinpath('Audio_data', 'val_list.txt')),\n",
    "    str(Path.cwd().parents[2].joinpath('Audio_data', 'test_list.txt'))\n",
    "]\n",
    "\n",
    "output_paths = [\n",
    "    str(Path.cwd().parents[2].joinpath('temporary_file', 'train.json')),\n",
    "    str(Path.cwd().parents[2].joinpath('temporary_file', 'val.json')),\n",
    "    str(Path.cwd().parents[2].joinpath('temporary_file', 'test.json'))\n",
    "]\n",
    "\n",
    "process_files(json_filename, txt_filenames, output_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc84006",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "def merge_shuffle_write_json(file_path1, file_path2, output_file):\n",
    "    with open(file_path1, 'r') as f1, open(file_path2, 'r') as f2:\n",
    "        data1 = json.load(f1)\n",
    "        data2 = json.load(f2)\n",
    "        merged_data = data1['data'] + data2['data']\n",
    "\n",
    "    random.shuffle(merged_data)\n",
    "\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump({'data': merged_data}, f, indent=2)\n",
    "\n",
    "\n",
    "input_file1 = str(Path.cwd().parents[2].joinpath('temporary_file', 'train.json'))\n",
    "input_file2 = str(Path.cwd().parents[2].joinpath('temporary_file', 'NoneOfTheAbove_train.json'))\n",
    "input_file3 = str(Path.cwd().parents[2].joinpath('temporary_file', 'opensource_segment.json'))\n",
    "output_file = str(Path.cwd().parents[2].joinpath('Audio_data', 'finetune_train.json'))\n",
    "merge_shuffle_write_json(input_file1, input_file2, input_file3, output_file)\n",
    "\n",
    "input_file1 = str(Path.cwd().parents[2].joinpath('temporary_file', 'val.json'))\n",
    "input_file2 = str(Path.cwd().parents[2].joinpath('temporary_file', 'NoneOfTheAbove_val.json'))\n",
    "output_file = str(Path.cwd().parents[2].joinpath('Audio_data', 'finetune_val.json'))\n",
    "merge_shuffle_write_json(input_file1, input_file2, output_file)\n",
    "\n",
    "input_file1 = str(Path.cwd().parents[2].joinpath('temporary_file', 'test.json'))\n",
    "input_file2 = str(Path.cwd().parents[2].joinpath('temporary_file', 'NoneOfTheAbove_test.json'))\n",
    "output_file = str(Path.cwd().parents[2].joinpath('Audio_data', 'finetune_test.json'))\n",
    "merge_shuffle_write_json(input_file1, input_file2, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "2fe113c2c5e0b59419e61147fb4b88aeced944e9e8c14aaecf71e1cf92ba4a25"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
